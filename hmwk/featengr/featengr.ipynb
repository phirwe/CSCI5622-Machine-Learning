{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering Homework \n",
    "***\n",
    "**Name**: Poorwa Hirve \n",
    "\n",
    "**Kaggle Username**: phirwe\n",
    "***\n",
    "\n",
    "This assignment is due on Moodle by **5pm on Friday February 23rd**. Additionally, you must make at least one submission to the **Kaggle** competition before it closes at **4:59pm on Friday February 23rd**. Submit only this Jupyter notebook to Moodle. Do not compress it using tar, rar, zip, etc. Your solutions to analysis questions should be done in Markdown directly below the associated question.  Remember that you are encouraged to discuss the problems with your instructors and classmates, but **you must write all code and solutions on your own**.  For a refresher on the course **Collaboration Policy** click [here](https://github.com/chrisketelsen/CSCI5622-Machine-Learning/blob/master/resources/syllabus.md#collaboration-policy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "***\n",
    "\n",
    "When people are discussing popular media, there’s a concept of spoilers. That is, critical information about the plot of a TV show, book, or movie that “ruins” the experience for people who haven’t read / seen it yet.\n",
    "\n",
    "The goal of this assignment is to do text classification on forum posts from the website [tvtropes.org](http://tvtropes.org/), to predict whether a post is a spoiler or not. We'll be using the logistic regression classifier provided by sklearn.\n",
    "\n",
    "Unlike previous assignments, the code provided with this assignment has all of the functionality required. Your job is to make the functionality better by improving the features the code uses for text classification.\n",
    "\n",
    "**NOTE**: Because the goal of this assignment is feature engineering, not classification algorithms, you may not change the underlying algorithm or it's parameters\n",
    "\n",
    "This assignment is structured in a way that approximates how classification works in the real world: Features are typically underspecified (or not specified at all). You, the data digger, have to articulate the features you need. You then compete against others to provide useful predictions.\n",
    "\n",
    "It may seem straightforward, but do not start this at the last minute. There are often many things that go wrong in testing out features, and you'll want to make sure your features work well once you've found them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle In-Class Competition \n",
    "***\n",
    "\n",
    "In addition to turning in this notebook on Moodle, you'll also need to submit your predictions on Kaggle, an online tournament site for machine learning competitions. The competition page can be found here:  \n",
    "\n",
    "[https://www.kaggle.com/c/feature-engineering-csci-5622-spring-2018](https://www.kaggle.com/c/feature-engineering-csci-5622-spring-2018)\n",
    "\n",
    "Additionally, a private invite link for the competition has been posted to Piazza. \n",
    "\n",
    "The starter code below has a `model_predict` method which produces a two column CSV file that is correctly formatted for Kaggle (predictions.csv). It should have the example Id as the first column and the prediction (`True` or `False`) as the second column. If you change this format your submissions will be scored as zero accuracy on Kaggle. \n",
    "\n",
    "**Note**: You may only submit **THREE** predictions to Kaggle per day.  Instead of using the public leaderboard as your sole evaluation processes, it is highly recommended that you perform local evaluation using a validation set or cross-validation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [25 points] Problem 1: Feature Engineering \n",
    "***\n",
    "\n",
    "The `FeatEngr` class is where the magic happens.  In it's current form it will read in the training data and vectorize it using simple Bag-of-Words.  It then trains a model and makes predictions.  \n",
    "\n",
    "25 points of your grade will be generated from your performance on the the classification competition on Kaggle. The performance will be evaluated on accuracy on the held-out test set. Half of the test set is used to evaluate accuracy on the public leaderboard.  The other half of the test set is used to evaluate accuracy on the private leaderboard (which you will not be able to see until the close of the competition). \n",
    "\n",
    "You should be able to significantly improve on the baseline system (i.e. the predictions made by the starter code we've provided) as reported by the Kaggle system.  Additionally, the top **THREE** students from the **PRIVATE** leaderboard at the end of the contest will receive 5 extra credit points towards their Problem 1 score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from nltk.stem.porter import *\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import nltk\n",
    "import string\n",
    "import math\n",
    "\n",
    "title = []\n",
    "year = []\n",
    "runtime = []\n",
    "season = []\n",
    "episodes = []\n",
    "genre = []\n",
    "\n",
    "title_year = dict()\n",
    "for line in open('../data/spoilers/title_year.csv'):\n",
    "    input_line = line.strip().split(',')\n",
    "    if input_line[0] not in title_year.keys():\n",
    "        title_year[input_line[0]] = round(float(input_line[1]), 3)\n",
    "    \n",
    "for line in open('../data/spoilers/tv_info.csv'):\n",
    "    input_line = line.strip().split('***')\n",
    "    if input_line[0] not in title:\n",
    "        title.append(input_line[0])\n",
    "        year.append(float(input_line[1]))\n",
    "        runtime.append(float(input_line[2]))\n",
    "        season.append(float(input_line[3]))\n",
    "        episodes.append(float(input_line[4]))\n",
    "\n",
    "# function most_common referred from:\n",
    "# https://stackoverflow.com/questions/1518522/python-most-common-element-in-a-list\n",
    "        \n",
    "import itertools\n",
    "import operator\n",
    "\n",
    "def most_common(L):\n",
    "    SL = sorted((x, i) for i, x in enumerate(L))\n",
    "    groups = itertools.groupby(SL, key=operator.itemgetter(0))\n",
    "    def _auxfun(g):\n",
    "        item, iterable = g\n",
    "        count = 0\n",
    "        min_index = len(L)\n",
    "        for _, where in iterable:\n",
    "            count += 1\n",
    "            min_index = min(min_index, where)\n",
    "        return count, -min_index\n",
    "    return max(groups, key=_auxfun)[0]\n",
    "\n",
    "class num_of_words(BaseEstimator, TransformerMixin):\n",
    "    def _init_(self):\n",
    "        pass\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "    def transform(self, examples):\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i=0\n",
    "        for ex in examples:\n",
    "            count = len(ex.split())\n",
    "            features[i,0] = count\n",
    "            i += 1\n",
    "        return features\n",
    "\n",
    "class adj_count(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "\n",
    "    def transform(self, examples):\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i = 0\n",
    "        for ex in examples:\n",
    "            text = word_tokenize(str(ex).translate(string.punctuation))\n",
    "            mylist = nltk.pos_tag(text)\n",
    "            count = 0\n",
    "            for item in mylist:\n",
    "                if item[1].lower() == 'jjs' or item[1].lower() == 'jjr':\n",
    "                    count += 1\n",
    "            features[i,0] = count\n",
    "            i += 1\n",
    "        return features\n",
    "    \n",
    "class adv_count(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "\n",
    "    def transform(self, examples):\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i = 0\n",
    "        for ex in examples:\n",
    "            text = word_tokenize(str(ex).translate(string.punctuation))\n",
    "            mylist = nltk.pos_tag(text)\n",
    "            count = 0\n",
    "            for item in mylist:\n",
    "                if item[1].lower() == 'rb':\n",
    "                    count += 1\n",
    "            features[i,0] = count\n",
    "            i += 1\n",
    "        return features\n",
    "    \n",
    "class capital_counts(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "    def transform(self, examples):\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i = 0\n",
    "        for ex in examples:\n",
    "            features[i,0] = sum(1 for letter in str(ex) if letter.isupper())\n",
    "            i += 1\n",
    "        \n",
    "        return features\n",
    "\n",
    "class Year(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "    def transform(self, examples):\n",
    "\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i = 0\n",
    "        for ex in examples:\n",
    "            try:\n",
    "#                 features[i,0] = year[title.index(str(ex))]\n",
    "                features[i,0] = title_year[str(ex)]\n",
    "            except:\n",
    "#                 features[i,0] = most_common(year)\n",
    "                features[i,0] = 1.0\n",
    "            i += 1\n",
    "        \n",
    "    \n",
    "class Season(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "    def transform(self, examples):\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i = 0\n",
    "        for ex in examples:\n",
    "            try:\n",
    "                features[i, 0] = season[title.index(str(ex))]\n",
    "            except:\n",
    "                features[i, 0] = most_common(season)\n",
    "            i += 1\n",
    "        return features\n",
    "    \n",
    "class Runtime(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "    def transform(self, examples):\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i = 0\n",
    "        for ex in examples:\n",
    "            try:\n",
    "                features[i, 0] = runtime[title.index(str(ex))]\n",
    "            except:\n",
    "                features[i, 0] = most_common(runtime)\n",
    "            i += 1\n",
    "        return features\n",
    "    \n",
    "class Episodes(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, examples):\n",
    "        return self\n",
    "    def transform(self, examples):\n",
    "        features = np.zeros((len(examples),1))\n",
    "        i = 0\n",
    "        for ex in examples:\n",
    "            try:\n",
    "                features[i, 0] = episodes[title.index(str(ex))]\n",
    "            except:\n",
    "                features[i, 0] = most_common(episodes)\n",
    "            i += 1\n",
    "        return features\n",
    "    \n",
    "def sentence_preprocess(examples):\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    new_examples = []\n",
    "    for ex in examples:\n",
    "        new_ex = [ps.stem(word) for word in word_tokenize(ex)]\n",
    "        new_examples.append(' '.join([wnl.lemmatize(word) for word in new_ex]))\n",
    "    return new_examples\n",
    "\n",
    "def trope_preprocess(examples):\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    new_examples = []\n",
    "    for ex in examples:\n",
    "        # https://stackoverflow.com/questions/37505224/add-a-space-between-each-word-in-the-string\n",
    "        ex = re.sub('([A-Z])', r' \\1', ex).strip()\n",
    "        new_ex = [wnl.lemmatize(word) for word in word_tokenize(ex)]\n",
    "        new_examples.append(' '.join([ps.stem(word) for word in new_ex]))\n",
    "    return new_examples\n",
    "\n",
    "class FeatEngr:\n",
    "    def __init__(self):\n",
    "\n",
    "        from sklearn.feature_extraction.text import CountVectorizer\n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        self.sentence_vectorizer = FeatureUnion([\n",
    "                                        ('num-of-words', num_of_words()),\n",
    "                                        ('adj-count', adj_count()),\n",
    "                                        ('adv-count', adv_count()),\n",
    "                                        ('capital-count', capital_counts()),\n",
    "                                        ('tfidf', TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1, 2), lowercase=True,\n",
    "                                          norm='l2'))])\n",
    "        self.trope_vectorizer = TfidfVectorizer(analyzer='word', stop_words='english', ngram_range=(1, 2), lowercase=True,\n",
    "                                          norm='l2')\n",
    "        self.year_vectorizer =  Year()\n",
    "        self.season_vectorizer = Season()\n",
    "\n",
    "    def build_train_features(self, examples, tropes, pages):\n",
    "        \"\"\"\n",
    "        Method to take in training text features and do further feature engineering\n",
    "        Most of the work in this homework will go here, or in similar functions\n",
    "        :param examples: currently just a list of forum posts\n",
    "        \"\"\"\n",
    "        prep_sentences = sentence_preprocess(examples)\n",
    "        prep_tropes = trope_preprocess(tropes)\n",
    "\n",
    "        sentence = self.sentence_vectorizer.fit_transform(prep_sentences)\n",
    "        trope = self.trope_vectorizer.fit_transform(prep_tropes)\n",
    "        year = self.year_vectorizer.fit_transform(pages)\n",
    "        season = self.season_vectorizer.fit_transform(pages)\n",
    "\n",
    "        vector = sp.sparse.hstack((sentence, trope, year, season))\n",
    "        \n",
    "        return csr_matrix(vector)\n",
    "\n",
    "    def get_test_features(self, examples, tropes, pages):\n",
    "        \"\"\"\n",
    "        Method to take in test text features and transform the same way as train features\n",
    "        :param examples: currently just a list of forum posts\n",
    "        \"\"\"\n",
    "\n",
    "        prep_sentences = sentence_preprocess(examples)\n",
    "        prep_tropes = trope_preprocess(tropes)\n",
    "\n",
    "        sentence = self.sentence_vectorizer.transform(prep_sentences)\n",
    "        trope = self.trope_vectorizer.transform(prep_tropes)\n",
    "        year = self.year_vectorizer.transform(pages)\n",
    "        season = self.season_vectorizer.transform(pages)\n",
    "        \n",
    "        vector = sp.sparse.hstack((sentence, trope, year, season))\n",
    "        return csr_matrix(vector)\n",
    "\n",
    "    def show_top10(self):\n",
    "        \"\"\"\n",
    "        prints the top 10 features for the positive class and the\n",
    "        top 10 features for the negative class.\n",
    "        \"\"\"\n",
    "        feature_names = np.asarray(self.vectorizer.get_feature_names())\n",
    "        top10 = np.argsort(self.logreg.coef_[0])[-10:]\n",
    "        bottom10 = np.argsort(self.logreg.coef_[0])[:10]\n",
    "        print(\"Pos: %s\" % \" \".join(feature_names[top10]))\n",
    "        print(\"Neg: %s\" % \" \".join(feature_names[bottom10]))\n",
    "\n",
    "\n",
    "    def train_model(self, random_state=1234):\n",
    "        \"\"\"\n",
    "        Method to read in training data from file, and\n",
    "        train Logistic Regression classifier.\n",
    "\n",
    "        :param random_state: seed for random number generator\n",
    "        \"\"\"\n",
    "\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        import pandas as pd\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        from sklearn.metrics import accuracy_score\n",
    "        from sklearn.model_selection import KFold\n",
    "        from scipy.sparse import csr_matrix\n",
    "\n",
    "        # load data\n",
    "        dfTrain = pd.read_csv(\"../data/spoilers/train.csv\")\n",
    "\n",
    "        # get training features and labels\n",
    "        self.X_train = self.build_train_features(list(dfTrain[\"sentence\"]), list(dfTrain[\"trope\"]), list(dfTrain[\"page\"]))\n",
    "        self.y_train = np.array(dfTrain[\"spoiler\"], dtype=int)\n",
    "        \n",
    "        self.logreg = LogisticRegression(random_state=random_state)\n",
    "        self.logreg.fit(self.X_train, self.y_train)\n",
    "        \n",
    "        from sklearn.model_selection import KFold\n",
    "        kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "        avg_accuracy = []\n",
    "        for train_index, test_index in kf.split(self.X_train):\n",
    "            k_X, k_x = self.X_train[train_index], self.X_train[test_index]\n",
    "            k_Y, k_y = self.y_train[train_index], self.y_train[test_index]\n",
    "            sentences = [list(dfTrain[\"sentence\"])[i] for i in test_index]\n",
    "            tropes = [list(dfTrain[\"trope\"])[i] for i in test_index]\n",
    "            pages = [list(dfTrain[\"page\"])[i] for i in test_index]\n",
    "\n",
    "            self.logreg = LogisticRegression(random_state=random_state)\n",
    "            self.logreg.fit(k_X, k_Y)\n",
    "            k_y_pred = self.logreg.predict(k_x)\n",
    "            print (accuracy_score(k_y, k_y_pred))\n",
    "            \n",
    "            self.error_analysis(k_x, k_y, k_y_pred, sentences, tropes, pages)\n",
    "\n",
    "            # TODO: Error analysis\n",
    "            avg_accuracy.append(accuracy_score(k_y, k_y_pred))\n",
    "        print('Average Accuracy is: ', sum(avg_accuracy) / len(avg_accuracy))\n",
    "\n",
    "\n",
    "    def model_predict(self):\n",
    "        \"\"\"\n",
    "        Method to read in test data from file, make predictions\n",
    "        using trained model, and dump results to file\n",
    "        \"\"\"\n",
    "\n",
    "        # read in test data\n",
    "        dfTest = pd.read_csv(\"../data/spoilers/test.csv\")\n",
    "\n",
    "        # featurize test data\n",
    "        self.X_test = self.get_test_features(list(dfTest[\"sentence\"]), list(dfTest['trope']), list(dfTest[\"page\"]))\n",
    "\n",
    "        # make predictions on test data\n",
    "        pred = self.logreg.predict(self.X_test)\n",
    "\n",
    "        # dump predictions to file for submission to Kaggle\n",
    "        pd.DataFrame({\"spoiler\": np.array(pred, dtype=bool)}).to_csv(\"prediction.csv\", index=True, index_label=\"Id\")\n",
    "\n",
    "        \n",
    "    def error_analysis(self, train, test, pred, sentences, tropes, pages):\n",
    "        pass\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "        C = confusion_matrix(test, pred)\n",
    "        print (C)\n",
    "        top_s = []\n",
    "        top_t = []\n",
    "        top_p = []\n",
    "        top_test = []\n",
    "        top_pred = []\n",
    "        for i in range(len(test)):\n",
    "            if test[i] != pred[i] and i <= 5:\n",
    "                top_s.append(sentences[i])\n",
    "                top_t.append(tropes[i])\n",
    "                top_p.append(pages[i])\n",
    "                top_test.append(test[i])\n",
    "                top_pred.append(pred[i])\n",
    "                \n",
    "        print (top_s)\n",
    "        print (top_t)\n",
    "        print (top_p)\n",
    "        print (top_test)\n",
    "        print (top_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.737677527151\n",
      "[[816 299]\n",
      " [329 950]]\n",
      "['The first episode deals with   one of the season 1 bad guys getting killed by an  Eldritch Abomination  with telekinesis!', \"Sure it's off-screen and its costume looks fake and silly, but still!\", 'Cheryl, Andy, and Dana make Jim think his dead friend came back to life, because Jim stole back his playing card that said friend stole the day before he died.']\n",
      "['DarkerAndEdgier', 'DarkerAndEdgier', 'PracticalJoke']\n",
      "['AaronStone', 'AaronStone', 'AccordingToJim']\n",
      "[1, 1, 0]\n",
      "[0, 0, 1]\n",
      "0.747702589808\n",
      "[[836 321]\n",
      " [283 954]]\n",
      "[\"For example in one episode Jim explains that men and women's brains are wired so they won't remember certain things, Cheryl gets mad at him, only to later find herself trapped in the garage because none of the girls can remember the key code for the door, which her toddler son punches in effortlessly.\", 'Andy has been a victim of this.']\n",
      "['DoubleStandard', 'GroinAttack']\n",
      "['AccordingToJim', 'AccordingToJim']\n",
      "[0, 0]\n",
      "[1, 1]\n",
      "0.722222222222\n",
      "[[808 358]\n",
      " [307 921]]\n",
      "['He also competed on  Chopped Tournament , where he   was chopped in the appetizer round .', 'Even after she returns in the middle of the charade.']\n",
      "['CrossOver', 'KarmaHoudini']\n",
      "['AceOfCakes', 'AdventuresInWonderland']\n",
      "[1, 0]\n",
      "[0, 1]\n",
      "0.734335839599\n",
      "[[800 318]\n",
      " [318 958]]\n",
      "[\" Kate + Eight  visited as a surprise for Kate; Guy Fieri came in for an episode of  Diners, Drive-ins and Dives  on Baltimore and Duff treated him to a giant cake shaped like a giant hamburger; Geof and Duff made an anniversary cake for  King of the Hill  and had cameos on the show; the crew traveled to Hawaii to  simultaneously  work on cakes for  Lost 's wrap party and a US military base (both groups loved it).\", 'Really  screwing up the flux capacitor caused Geof and Duff to become workers at a cake box factory .']\n",
      "['CrossOver', 'TimeTravel']\n",
      "['AceOfCakes', 'AceOfCakes']\n",
      "[0, 1]\n",
      "[1, 0]\n",
      "0.723475355054\n",
      "[[800 326]\n",
      " [336 932]]\n",
      "['The end of \"Mutant Rain\" has him reveal his face to Aaron and the rest of his team.', 'Too bad for them a woman ends up the winner.', 'In \"Her-story in the Making\", Alice tries getting her Wonderland friends to write a story for her school assignment for her.']\n",
      "['FaceFramedInShadow', 'EatingContest', 'TooManyCooks']\n",
      "['AaronStone', 'AccordingToJim', 'AdventuresInWonderland']\n",
      "[0, 0, 0]\n",
      "[1, 1, 1]\n",
      "Average Accuracy is:  0.733082706767\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the FeatEngr clas \n",
    "feat = FeatEngr()\n",
    "\n",
    "feat.train_model(random_state=1230)\n",
    "feat.model_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [25 points] Problem 2: Motivation and Analysis \n",
    "***\n",
    "\n",
    "The job of the written portion of the homework is to convince the grader that:\n",
    "\n",
    "- Your new features work\n",
    "- You understand what the new features are doing\n",
    "- You had a clear methodology for incorporating the new features\n",
    "\n",
    "Make sure that you have examples and quantitative evidence that your features are working well. Be sure to explain how you used the data (e.g., did you have a validation set? did you do cross-validation?) and how you inspected the results. In addition, it is very important that you show some kind of an **error analysis** throughout your process.  That is, you should demonstrate that you've looked at misclassified examples and put thought into how you can craft new features to improve your model. \n",
    "\n",
    "A sure way of getting a low grade is simply listing what you tried and reporting the Kaggle score for each. You are expected to pay more attention to what is going on with the data and take a data-driven approach to feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "___\n",
    "\n",
    "# Solution:\n",
    "---\n",
    "\n",
    "\n",
    "## Cross Validation:\n",
    "- I first manually divided the training data into 5 folds, running the classifier 5 times.\n",
    "- Next, I decided to use sklearn's KFold for cross validation\n",
    "\n",
    "## Preprocessing:\n",
    "- I stemmed and lemmatized sentences and tropes. Preprocessing brought the accuracy up.\n",
    "\n",
    "## Feature Selection:\n",
    "\n",
    "### N-grams\n",
    "- At first, I selected a trigram model. On increasing the folds to 10, I noticed that the trigram model did not work that well.\n",
    "- Next I decided to use bigrams. Its performance was better than trigrams.\n",
    "\n",
    "### Length of the Sentence\n",
    "- Upon looking into the 'train.csv' file, I discovered that the more the length of the sentences, the more likely it was to be a spoiler.\n",
    "\n",
    "### Parts of Speech\n",
    "- Upon error analysis of the mislabelled examples, that is printing the sentences that were mislabelled, I noticed that sentences containing spoilers had more adjectives and adverbs, that is with parts of speech 'JJR', 'JJS' and 'RB'.\n",
    "\n",
    "### Capital Letters\n",
    "- Most spoilers contain character names or episode titles, which have many capital letters that influence the decision.\n",
    "\n",
    "### TfIdf\n",
    "- This is a feature to decide how important a word is to a document in a collection. Bigrams were used along with the TfidfVectorizer for sentences as well as tropes.\n",
    "\n",
    "### Years, Seasons\n",
    "- The more recent TV shows would be more likely to contain spoilers, and shows that long running shows would have stories that develop and have spoilers.\n",
    "\n",
    "## Results\n",
    "\n",
    "I achieved an average accuracy of 73% on Cross Validation with 5 folds.\n",
    "On Kaggle, I achieved top 2 accuracies of 72.72% and 72.31%.\n",
    "\n",
    "\n",
    "## Features and their effect on the accuracy\n",
    "\n",
    "| Feature                | Effect on Accuracy |\n",
    "|------------------------|----------------------|\n",
    "|Count of Quotation Marks| Decreased            |\n",
    "|Count of Proper Nouns   | Decreased            |\n",
    "|5-grams | Decreased |\n",
    "|Trigrams                | Decreased            |\n",
    "|Bigrams                 | Increased            |\n",
    "|Year (difference from now)|Decreased           |\n",
    "|Year (Normalizing) | Increased |\n",
    "|Length of Sentence | Increased |\n",
    "|Capital Letters | Increased |\n",
    "|Tfidf | Increased |\n",
    "|Seasons | Increased |\n",
    "|Runtime | Decreased |\n",
    "\n",
    "\n",
    "## Data From IMDb\n",
    "\n",
    "I obtained the TV series information from IMDb using imdbpy and stored it all in a file called 'tv_info.csv'.\n",
    "\n",
    "---\n",
    "___\n",
    "\n",
    "## Error Analysis\n",
    "\n",
    "The error_analysis function shows some of the misclassified examples and what they were misclassified as. I made use of that function to find out which features had more impact. On observing the misclassified sentences and the training data corresponding to them, I was able to improve the model by trying out different features. I also used a confusion matrix for error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Hints \n",
    "***\n",
    "\n",
    "- Don't use all the data until you're ready. \n",
    "\n",
    "- Examine the features that are being used.\n",
    "\n",
    "- Do error analyses.\n",
    "\n",
    "- If you have questions that aren’t answered in this list, feel free to ask them on Piazza.\n",
    "\n",
    "### FAQs \n",
    "***\n",
    "\n",
    "> Can I heavily modify the FeatEngr class? \n",
    "\n",
    "Totally.  This was just a starting point.  The only thing you cannot modify is the LogisticRegression classifier.  \n",
    "\n",
    "> Can I look at TV Tropes?\n",
    "\n",
    "In order to gain insight about the data yes, however, your feature extraction cannot use any additional data (beyond what I've given you) from the TV Tropes webpage.\n",
    "\n",
    "> Can I use IMDB, Wikipedia, or a dictionary?\n",
    "\n",
    "Yes, but you are not required to. So long as your features are fully automated, they can use any dataset other than TV Tropes. Be careful, however, that your dataset does not somehow include TV Tropes (e.g. using all webpages indexed by Google will likely include TV Tropes).\n",
    "\n",
    "> Can I combine features?\n",
    "\n",
    "Yes, and you probably should. This will likely be quite effective.\n",
    "\n",
    "> Can I use Mechanical Turk?\n",
    "\n",
    "That is not fully automatic, so no. You should be able to run your feature extraction without any human intervention. If you want to collect data from Mechanical Turk to train a classifier that you can then use to generate your features, that is fine. (But that’s way too much work for this assignment.)\n",
    "\n",
    "> Can I use a Neural Network to automatically generate derived features? \n",
    "\n",
    "No. This assignment is about your ability to extract meaningful features from the data using your own experimentation and experience.\n",
    "\n",
    "> What sort of improvement is “good” or “enough”?\n",
    "\n",
    "If you have 10-15% improvement over the baseline (on the Public Leaderboard) with your features, that’s more than sufficient. If you fail to get that improvement but have tried reasonable features, that satisfies the requirements of assignment. However, the extra credit for “winning” the class competition depends on the performance of other students.\n",
    "\n",
    "> Where do I start?  \n",
    "\n",
    "It might be a good idea to look at the in-class notebook associated with the Feature Engineering lecture where we did similar experiments. \n",
    "\n",
    "\n",
    "> Can I use late days on this assignment? \n",
    "\n",
    "You can use late days for the write-up submission, but the Kaggle competition closes at **4:59pm on Friday February 23rd**\n",
    "\n",
    "> Why does it say that the competition ends at 11:59pm when the assignment says 4:59pm? \n",
    "\n",
    "The end time/date are in UTC.  11:59pm UTC is equivalent to 4:59pm MST.  Kaggle In-Class does not allow us to change this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python [anaconda]",
   "language": "python",
   "name": "Python [anaconda]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
